{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2_PythonReview.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QMukh9KVrge"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1jkVzPlJe1indZnIGzG9S45F5O27tppCs?usp=sharing)\n",
        "\n",
        "*Note: GitHub.com does not render everything when viewing these notbeook files, so click the \"Open in Colab\" button above to see everything as it's intended.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6q0qF7gm5Rwf"
      },
      "source": [
        "# Python/Jupyter Review\n",
        "\n",
        "This course assumes some \"basic\" familiarity with Python (cf. [\"Learn the Basics\" at LearnPython.org](https://www.learnpython.org/)).  We're not going to be doing what I'd call \"hardcore\" Python, and many \"hard\" things will be taken care of for you via utility routines so you'll often only have to \"fill in the blanks\" here and there.\n",
        "\n",
        "Still, there's likely some need for review as well as to highlight important \"tricks\", and things you maybe haven't seen before. In particular, we'll be making use of the \"science stack\" (e.g., `numpy`, `matplotlib`,a little `pandas`) but not the \"web stack\" (e.g. not Flask or Django).  So, let's make a list of things you'll see in this course...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qyzKWtruZA5"
      },
      "source": [
        "## Key Points about Python \n",
        "\n",
        "### It's superb for \"messing around\"\n",
        "> \"*Decades of programming in strongly-typed, declarative, pre- and post-allocation-based languages held me back from 'getting' this key fact about Python: It's extremely well-suited for **messing around**, ...and one of best playgrounds for messing around in is the Jupyter notebook environment.*\" - S.H.\n",
        "\n",
        "Everything is mutable, everything is overridable, everything is extendable. This is a blessing and a curse. For years I was preoccupied with the curse part, but you'll do well to remember the blessing side: you can do what you want (within limits)! \n",
        "<center><img src=\"https://d3qdvvkm3r2z1i.cloudfront.net/media/catalog/product/cache/1/thumbnail/85e4522595efc69f496374d01ef2bf13/d/o/dowhatiwant_newthumb-again.png\" width=\"25%\"></center>\n",
        "\n",
        "It's not obvious that you'd want to write production code in Python: it *can* be fast, but it's not secure *at all*; for learning things and rapid prototyping though, it's awesome. \n",
        "\n",
        "### There's a Library/Package for Everything\n",
        "I think this is another key to Python's success. Other languages have some of this (e.g. JavaScript & npm), but with Python there really is already some package that will do much of the heavy lifting for you if you want.\n",
        "\n",
        "### Writing Fast Python is a 'Habit'\n",
        "\n",
        "Speed matters for deep learning because we'll be dealing with *gajillions* of calculations, and a the difference between 10 microseconds vs. 10 milliseconds per operation will make the difference between you getting an answer to a homework problem in a few minutes vs. a few *days*.  (Again, this is a different mindset than, say, web programming in Python, where speed matters a bit but not nearly as much.)\n",
        "\n",
        "<center><img src=\"https://i2.wp.com/comicsandmemes.com/wp-content/uploads/Famous-Movie-Qoutes-1986-Top-Gun-I-feel-the-need-for-speed.jpg?resize=768%2C401&ssl=1\" width=\"40%\"></center>\n",
        "\n",
        "When you're first starting out, it's easy to accidentally write *really slow* code, particularly if you're coming from other programming languages. Learning to think in terms of \"vectorized\" operations and writing \"one-liners\" (e.g. \"list comprehensions\" which often are faster that multi-line implementations) can take some getting used to but eventually becomes a habit. So in what follows, we'll talk about few speedy ways of \"prasing\" things when writing Python code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSTEKf0Q50_f"
      },
      "source": [
        "## Jupyter notebooks / Colab\n",
        "\n",
        "You could write raw Python code as a text file and execute in the command-line (I used to do this), or use some IDE like PyCharm, but for this course we'll need access to **other people's computers** that give us access to GPUs (Graphics Processing Units) that we'll use for heavy number-crunching -- again, speed is key. \n",
        "\n",
        "Everything for this course is designed to be run on [Google Colab]() which is kind of a Google-Flavored version of the Jupyter environment. So, when I say \"Jupyter notebooks\", I mean like what the file I'm writing right now, regardless of whether it's hosted in an actual Jupyter environment (e.g. on Paperspace Gradient) or on Colab. Generally I'll assume Colab. \n",
        "\n",
        "(There are some special things you can do in regular-Jupyter that you can't do on Colab, and probably vice versa, but I'll try to minimize mention of those.) \n",
        "\n",
        "**TODO: come back and fill these in:**\n",
        "* REPL\n",
        "* Cell navigation\n",
        "* Special moves: \n",
        "    * `!` shell commands \n",
        "    * `%` \"magic\" \n",
        "    * `?` documentation tricks \n",
        "* Colab vs. Jupyter\n",
        "* Jupyter vs. IPython?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKKk6AQ75VS5"
      },
      "source": [
        "\n",
        "\n",
        "## Imports, Packages and Modules\n",
        "\n",
        "**TODO:** Say something here.\n",
        "\n",
        "\"How do I make my own Python package?\" is something we can cover later. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BinbB-xEUEof"
      },
      "source": [
        "## Key Packages For Us \n",
        "* **NumPy**: We're going to use the numerical package NumPy a *lot*, and when we compute things involving neural networks we'll use... \n",
        "* **PyTorch** for GPU-based computation. Our neural network calculations will typically exist \"in\" PyTorch.  PyTorch which has routines that are usually have the same name (though not always the same keyword arguments!) as the corresponding NumPy routines. \n",
        "* **FastAI** (also fast.ai or fastai) offers some powerful and convenient abstractions on top of PyTorch and some great integrations with other technologies, so we'll use it as well. \n",
        "* **MrsPuff:** And special just for this course, I've been creating a library called \"[mrspuff](https://github.com/drscotthawley/mrspuff)\" that will provide other useful functions for  things I want to teach you.\n",
        "<center><img src=\"https://github.com/drscotthawley/mrspuff/raw/master/images/mrspuff_logo.png?raw=1\" width=\"50%\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZLa6mC7wofc"
      },
      "source": [
        "Let's make sure we can install and import our key packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZxbMAEEUcAI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da0f103-b39b-472a-8907-9a6b74ae7734"
      },
      "source": [
        "# mrspuff already requires the other packages, so pip will grab them all\n",
        "!pip install mrspuff | grep -v already\n",
        "\n",
        "# Let's try to import our core packages\n",
        "import numpy as np      # Everybody always abbreviates numpy as np\n",
        "import torch            # The package for PyTorch is actually \"torch\" \n",
        "import fastai           # Usually we'll do \"from fastai.xxxx import *\"\n",
        "import mrspuff as msp   # We may instead do \"from mrspuff.xxxx import this, that\n",
        "\n",
        "for p in [torch,fastai,msp]:  # Let's see what package versions we have\n",
        "    print(f'{p.__name__} {p.__version__}')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch 1.7.1\n",
            "fastai 2.3.0\n",
            "mrspuff 0.0.23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYKM7UM75Lqn"
      },
      "source": [
        "### NumPy particulars\n",
        "\n",
        "Most of the things on this page might be review for many people, but the numpy content is crucial.  The basic datatype for numpy is the *array*, which is like a regular Python list but with many key improvements for (fast) numerical computations. \n",
        "\n",
        "#### Creating Arrays\n",
        "There are lots of ways to create arrays, such as converting a list, or by using a special routines for special sets of numbers.  Here are some examples:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Rx9Geppy1-V",
        "outputId": "2dc82bbd-5a4f-4f68-ac15-0cc6c0fa27e7"
      },
      "source": [
        "a= np.array([1,2,3,4,5,6])\n",
        "print(f'a = {a}')\n",
        "b = np.arange(6) # starts with 0, ends at 5\n",
        "print(f'b = {b}')\n",
        "print(f'c = {np.ones(6)}')\n",
        "print(f'd = {np.zeros(7)}')\n",
        "print(f\"e = \\n{np.eye(3)}\")     # identity matrix \"I\" = \"eye\"\n",
        "f = np.random.rand(4,5)         # random numbers between 0 and 1: 4 rows, 5 columns\n",
        "print(f'f = \\n{f}') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = [1 2 3 4 5 6]\n",
            "b = [0 1 2 3 4 5]\n",
            "c = [1. 1. 1. 1. 1. 1.]\n",
            "d = [0. 0. 0. 0. 0. 0. 0.]\n",
            "e = \n",
            "[[1. 0. 0.]\n",
            " [0. 1. 0.]\n",
            " [0. 0. 1.]]\n",
            "f = \n",
            "[[0.20783574 0.76401478 0.23911842 0.90923213 0.98171159]\n",
            " [0.42841005 0.46869862 0.90547014 0.42834658 0.3942568 ]\n",
            " [0.39143915 0.75108092 0.80054246 0.15198811 0.06094724]\n",
            " [0.2609732  0.68546969 0.55893476 0.04835097 0.21794896]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O7xG8pt0NbK"
      },
      "source": [
        "#### Array Properties & Operations\n",
        "* `shape` gives the number of rows and columns.  This is probably the most important property you will need to be checking and getting right! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijzuQSve0Y-6",
        "outputId": "68ed3ef9-ec8f-42ca-b627-c92edc64325b"
      },
      "source": [
        "f.shape "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydq2NCU70f98"
      },
      "source": [
        "* mathematical operations, which are eitherappended with a `.` or prepended with an `np.` (sometimes either way, sometimes only one way), e.g.:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_8McqRx0sJM",
        "outputId": "eff313ed-44ab-4121-f23c-37eb5e3621c1"
      },
      "source": [
        "print(f'f.mean() = {f.mean()}')\n",
        "print(f'np.abs(f) = \\n{np.abs(f)}')  # absolute value, note it's np.abs(f) not f.abs() ?\n",
        "# the axis keyword can say along which axis (rows, columns..) the op is applied over\n",
        "print(f'np.mean(f, axis=0) = {np.mean(f, axis=0)}')   \n",
        "print(f'np.max(f,axis=1) = {np.max(f,axis=1)}')  # gets the max element \n",
        "print(f'np.argmax(f,axis=1) = {np.argmax(f,axis=1)}')  # gets the location of the max element \n",
        "print(f'f.sum(axis=1) = {f.sum(axis=1)}')\n",
        "print(f'f.T = \\n{f.T}')  # Transpose, reverses rows & columns\n",
        "print(f'f.shape = {f.shape}, f.T.shape = {f.T.shape}')\n",
        "# change the rows x column shape but # of elements must remain unchanged:\n",
        "print(f'np.reshape(f, (2,10))  = \\n{np.reshape(f, (2,10))}')  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f.mean() = 0.48273851513282884\n",
            "np.abs(f) = \n",
            "[[0.20783574 0.76401478 0.23911842 0.90923213 0.98171159]\n",
            " [0.42841005 0.46869862 0.90547014 0.42834658 0.3942568 ]\n",
            " [0.39143915 0.75108092 0.80054246 0.15198811 0.06094724]\n",
            " [0.2609732  0.68546969 0.55893476 0.04835097 0.21794896]]\n",
            "np.mean(f, axis=0) = [0.32216453 0.667316   0.62601644 0.38447945 0.41371615]\n",
            "np.max(f,axis=1) = [0.98171159 0.90547014 0.80054246 0.68546969]\n",
            "np.argmax(f,axis=1) = [4 2 2 1]\n",
            "f.sum(axis=1) = [3.10191266 2.62518219 2.15599788 1.77167758]\n",
            "f.T = \n",
            "[[0.20783574 0.42841005 0.39143915 0.2609732 ]\n",
            " [0.76401478 0.46869862 0.75108092 0.68546969]\n",
            " [0.23911842 0.90547014 0.80054246 0.55893476]\n",
            " [0.90923213 0.42834658 0.15198811 0.04835097]\n",
            " [0.98171159 0.3942568  0.06094724 0.21794896]]\n",
            "f.shape = (4, 5), f.T.shape = (5, 4)\n",
            "np.reshape(f, (2,10))  = \n",
            "[[0.20783574 0.76401478 0.23911842 0.90923213 0.98171159 0.42841005\n",
            "  0.46869862 0.90547014 0.42834658 0.3942568 ]\n",
            " [0.39143915 0.75108092 0.80054246 0.15198811 0.06094724 0.2609732\n",
            "  0.68546969 0.55893476 0.04835097 0.21794896]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmqTuSEO3QPY"
      },
      "source": [
        "* **Vectorizing** = speed. Treat arrays as single objects, then operations can be applied to all elements at once very quickly. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kPbkM0L38uv"
      },
      "source": [
        "g = np.random.rand(1000,10000)   # define lots of numbers"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wi4iBAL43RJp",
        "outputId": "9fa7d594-4a26-4af1-fb1c-d779eb5d1d4a"
      },
      "source": [
        "%%timeit                # handy trick for timing code\n",
        "a = g/2  # treat f like a sigle thing"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 5: 15.2 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiaTcjqs3jO-",
        "outputId": "062c167b-4f5b-49bd-9e91-752ec0052215"
      },
      "source": [
        "%%timeit\n",
        "a = np.empty(g.shape)\n",
        "for i in range(g.shape[0]):\n",
        "    for j in range(g.shape[1]):\n",
        "        a = g[i,j]/2      # try to operate on each element in succession"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 5.85 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruxh5Zo25WGK"
      },
      "source": [
        "* **Slicing** is super-important. It's how we specify subsets of arrays. Typicaly this is done with numbers specifying array indices to slice at, the colon `:` to denote \"wildcard\" values, and commas to separate axes. Note that tegative indices are counted backwards from the end of the arrray. Here are some examples:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OoULRkt6Ose",
        "outputId": "ca026aec-6369-4877-da2d-528d0231da6f"
      },
      "source": [
        "a = np.arange(12).reshape((3,4))\n",
        "print(f'a = \\n{a}')\n",
        "print(f'a[:,2] = {a[:,2]}')  # the second column; but not it will become a 1.array\n",
        "print(f'a[:,2,np.newaxis] = \\n{a[:,2,np.newaxis]}') # newaxis can create an axis if one was lost\n",
        "print(f'a[1:,:-1] = {a[1:,-1]}') # all rows after the first one, and the last column\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = \n",
            "[[ 0  1  2  3]\n",
            " [ 4  5  6  7]\n",
            " [ 8  9 10 11]]\n",
            "a[:,2] = [ 2  6 10]\n",
            "a[:,2,np.newaxis] = \n",
            "[[ 2]\n",
            " [ 6]\n",
            " [10]]\n",
            "a[1:,:-1] = [ 7 11]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_HRyvJW7sLe"
      },
      "source": [
        "Sliced sections of arrays are called \"views\": they are are not re-generated as new arrays, they are just \"views\" of the old array.  If you want to add or operate on slices of arrays, they must have the same shape.\n",
        "\n",
        "*Tip:* Note that array indexes can *only* be integers, and that Python division via `/` naturally produces floats, so if your slicing involves division you may need to wrap it in an `int()` type cast. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBeKEJ9f8RyL"
      },
      "source": [
        "* **Broadcasting** is the exception to arrays being the same shape.  It lets you combine a large array with a smaller one in certain ways:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSGyztoD8QKp",
        "outputId": "68307206-51be-4879-ad0f-3a424743871d"
      },
      "source": [
        "print(f\"a + 5 = \\n{a+5}\") # We can broadcast scalars\n",
        "try: print(f\"a + np.ones(2) = {a+np.ones(2)}\")\n",
        "except ValueError: \n",
        "    print(\"ValueError: operands could not be broadcast together with shapes (3,4) (2,)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a + 5 = \n",
            "[[ 5  6  7  8]\n",
            " [ 9 10 11 12]\n",
            " [13 14 15 16]]\n",
            "ValueError: operands could not be broadcast together with shapes (3,4) (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNIMaBN_8o0E"
      },
      "source": [
        "Ohhh woopsie.  See, the shapes didn't match. How about if we match the last dimension (4)...?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z6Rm2Ku8voz",
        "outputId": "79564fbc-f2c3-43b4-d9e2-dc7d6aeac1ed"
      },
      "source": [
        "print(f\"a + np.ones(3) = \\n{a+np.ones(4)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a + np.ones(3) = \n",
            "[[ 1.  2.  3.  4.]\n",
            " [ 5.  6.  7.  8.]\n",
            " [ 9. 10. 11. 12.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoHbfUuZ8_Ax"
      },
      "source": [
        "Good. See, in order for arrays to be in joint operations together, the *last dimension* (in this cas 4) has to be the same.  What NumPy does is it creates a \"broadcast view\" of the smaller array to where it's the same size as the big array, i.e. it creates, in the example above, a 3x4 array of ones out of the 4-element array of ones. Then it adds these two \"big arrays\" together. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWFPizSCylYJ"
      },
      "source": [
        "* `random` and seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ3o3gL1Heu3"
      },
      "source": [
        "## Functions & Methods\n",
        "\n",
        "TODO: say something general here. \n",
        "\n",
        "### lambda is just a function with no name\n",
        "I'm not going to make you write \"lambda\" functions, but if you see one don't worry, it's the same as an unnamed function (e.g. there's no \"def __name__()\"). And because everything is mutable, you can *give it* name. So the following 3 snippets do the same thing:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJYMFI6aHePH",
        "outputId": "0f3f022b-8528-4e2a-9f43-58cf3702fa42"
      },
      "source": [
        "def a(x): return x+5\n",
        "print(\"a =\",a(4))\n",
        "\n",
        "b = lambda x: x+5 \n",
        "print(f\"b = {b(4)}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = 9\n",
            "b = 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfjpNE6XH_Ak"
      },
      "source": [
        "...Oh yea, see in that last line I used a \"f-string.\" They've been a feature since Python 3.5. We'll use them a lot because I think they're great. But if you try to use an older Python interpreter (e.g. Python 2.7), you'll get a syntax error.  Actually everything we'll be doing will assume at least Python 3.6. Let's see what version we're running:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmCHWygOIT83",
        "outputId": "26562478-6027-4e3a-ab38-80dfdb195e09"
      },
      "source": [
        "import sys\n",
        "print(f\"Python version is {sys.version}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python version is 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aFZDmAEJV8C"
      },
      "source": [
        "### Generators are not that bad\n",
        "A [generator](https://www.learnpython.org/en/Generators) is just a function with the word \"yield\" in it (which functions kind of like \"return\") and they can be used as iterators (e.g. for for loops & list comprehensions).  Here's a generator. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIG1hdfDJS87",
        "outputId": "1ac91d32-245a-462d-82fb-0e2098a233a4"
      },
      "source": [
        "def gen(z, step=1):\n",
        "    count = 0\n",
        "    for i in range(z):       # this is a standard for loop, see below\n",
        "        count += step\n",
        "        yield(count)\n",
        "\n",
        "print([x for x in gen(10)])  # this is a list comprehension, see below\n",
        "print([x for x in gen(10,step=-2)])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
            "[-2, -4, -6, -8, -10, -12, -14, -16, -18, -20]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yU6uor8fLCOm"
      },
      "source": [
        "They are often use to supply the next batch of data to something, like we'll do when training our neural networks.  But this will mostly be done for us by our library routines; I don't think you'll need to write your own generators. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4B9oamgjWrXd"
      },
      "source": [
        "\n",
        "## Classes \n",
        "and namespaces\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X8o-3bvI04ch"
      },
      "source": [
        " \n",
        "\n",
        "## Data types\n",
        "\n",
        "\n",
        "### Lists \n",
        "\n",
        " \n",
        "\n",
        "### Dictionaries \n",
        "[Dictionaries](https://www.learnpython.org/en/Dictionaries) are great, especially as fast \"[hashes](https://en.wikipedia.org/wiki/Hash_function)\", i.e. as fast look-up-functions between two sets of data.  The Pandas data science library is largely based on dictionaries. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPsI9sdTSVc5"
      },
      "source": [
        "## Loops\n",
        "Different ways of writing loops can be faster or slower than others, and it depends on the application and the number of iterations. Generally,\n",
        "* Try avoid loops for simple things, instead prefer vectorized numpy operations, e.g. use `.mean()` on a NumPy array instead of  looping over all elements and keeping a running sum and then dividing by the number of iterations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YMdDm88Sbsk"
      },
      "source": [
        "arr = np.random.rand(99999999)  # generate lots o' numbers"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIAwpTOhSbgn",
        "outputId": "22472866-9dfe-4e88-ddc1-0cad880c8271"
      },
      "source": [
        "%%timeit\n",
        "arr.mean()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 72.4 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNQQ3inrSbTj",
        "outputId": "236e527d-e937-4e07-d153-9beaf0007c6e"
      },
      "source": [
        "%%timeit \n",
        "sum, n = 0, len(arr)\n",
        "for i in range(n):\n",
        "    sum += arr[i]\n",
        "mean = sum/n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 5: 27 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxcZZBcnTwHD"
      },
      "source": [
        "...yeah.  Which one is faster?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lVlObd35cAu"
      },
      "source": [
        "\n",
        "* When we write loops, there are 3 main ways we do it. Letting y denone some iterator such as `range(n)` or a list, then these 3 ways are:\n",
        "   1. standard loops: `for x in y: _somthing_involving_x` (and yes, loops can be one-liners or they can span multiple lines)\n",
        "   2. list comprehensions: `[_somthing_involving_x for x in y]`\n",
        "   3. (more advanced) `map` operations: `_some_list_ = list(map(func, y))`\n",
        "\n",
        "Handy loop iterators:\n",
        "* range \n",
        "* enumerate() & zip() \n",
        "\n",
        "If you're looping in order to build up a bunch of data or do a bunch of single operations, then [List comprehensions](https://www.learnpython.org/en/List_Comprehensions) usually preferable.  \n",
        "\n",
        "Let's do a comparison:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5P2II5D5EhC"
      },
      "source": [
        "## Plotting:\n",
        "* matplotlib \n",
        "* Others"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pq05ryRN00JH"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDduonc45HkJ"
      },
      "source": [
        "## Pandas stuff:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jxzBzrW_NR9"
      },
      "source": [
        "# Practice Exercises\n",
        "These exercises are for your practice. These are in contrast to Homework assignments, which will be graded (automatically by an autograder program)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sX7cH7_d_dO0"
      },
      "source": [
        "1. Create a function called \"square_half\" that will accept a positive integer n, and from that return two arrays. The first will be an array of successive values from 1 to n, and the second will consist of only the first n/2 perfect squares. Hint: Note that you might need to wrap something in an \"int()\". "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmPD29-z_O-O"
      },
      "source": [
        "def square_half(n):  # Don't change this line\n",
        "    # Your code here. You may assume n is a positive integer, but feel free to check for this! \n",
        "\n",
        "    return    # return two arrays, separated by a comma"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3M07lFSGA7Y"
      },
      "source": [
        "You can test your function with the following code. If any of these fail and you can't figure out why, you may want to try giving a small number for `n` and then add `print` statements to see what your arrays actually contain. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6vi064uGAVS",
        "outputId": "5a846621-e415-4bea-ebd7-e57be88eb951"
      },
      "source": [
        "n = 10000\n",
        "a, a_sq = square_half(n)\n",
        "\n",
        "no2 = int(n/2)\n",
        "assert a.shape[0]==n, f\"You should have {n} values in the first array but instead you have {a.shape[0]}\"\n",
        "assert a_sq.shape[0]==no2, f\"You should have {no2} values in the 2nd array but instead you have {a_sq.shape[0]}\"\n",
        "assert np.array_equal(np.ones(n)*(n+1), a+a[::-1]) and ((a[1:]-a[:-1]).sum())==n-1, '...successive values...'\n",
        "assert a[0] == 1, \"...from 1...\"\n",
        "assert a[-1] == n, f\"...to n,\"\n",
        "assert np.array_equal(a_sq/a[:no2], a[:no2]), '...consisting of...perfect squares'\n",
        "\n",
        "import time\n",
        "n = 10000000\n",
        "start = time.perf_counter()\n",
        "a, a_sq = square_half(n)\n",
        "stop = time.perf_counter()\n",
        "elapsed = stop-start\n",
        "assert elapsed  < 0.035, f\"Elapsed time = {elapsed} s. Results are correct but could be obtained faster. Try again.\"\n",
        "print(\"All checks passed! Congratulations!\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All checks passed! Congratulations!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWpw6TfrFc4M"
      },
      "source": [
        "These kinds of \"assertion checks\" are exactly how your homework assignments will be auto-graded:  The autograder script will call your function with various inputs and check them against expected outputs. "
      ]
    }
  ]
}