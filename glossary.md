# Glossary of DL Terms

| A                                                            |                                                              |
| :----------------------------------------------------------- | :----------------------------------------------------------- |
| Term                                                         | Definition                                                   |
| Activation [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | A nonlinear function applied at the output of a neuron, i.e. after the weighted sum. Many choices of activations are used, such as ReLU (see Rectifier), sigmoid (see Regression), tanh, and more. In DL, all activations must be differentiable (i.e. continuous functions) in order to admit training via Gradient Descent, though the earliest artificial neurons used discontinuous "step functions". |
| AGI [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Artificial General Intelligence, aka "Strong AI". A machine that can emulate a human for any and all cognitive tasks. Not a real thing anytime soon, may not be possible or meaningful, but the stated goal of several notable Deep Learning & AI researchers. Not a topic in this course. We will only be covering "Weak AI" / "Narrow AI". |
| AI Ethics [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | For this course, we primarily mean consideration of the *impacts* of automated systems on individual humans and on society. In this course, "AI Ethics" applies to the ethical *use or application of* AI, in ways that minimize harm and promote human flourishing. It is very similar to "Business Ethics when AI is used." See "[Artificial Intelligence and Ethics: Sixteen Challenges and Opportunities](https://belmont.blackboard.com/webapps/blackboard/glossary/links/Artificial Intelligence and Ethics: Sixteen Challenges and Opportunities)" by Brian Patrick Green (2020) for examples.In contrast, "Machine Ethics" is the term typically used for trying to design AI systems (& robots) that behave in ways that mimic humans' ethical choices -- AIs "behaving ethically" if you will. We will not be covering Machine Ethics in this course. Also for the purposes of this course, topics such as "AI Safety", "The Alignment Problem", "Roko's Basilisk", "The Singularity", "Superintelligence", and cocerns of people like Nick Bostrom, Elon Musk, etc, will be grouped in with Machine Ethics. "Anthropomorphic" pseudo-ethical questions of "Is a robot alive?", "Do machines have souls?", "Is it murder to switch off Sophia the Robot?", etc. are also outside the scope of this course. |
| API [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Abstract Programming Interface. The "calling sequence" for a subroutine or service. Many web services (and certain big DL language models) are available via APIs defined by the company (e.g. the Twitter API, then OpenAI API). The API is the means and protocol by which you interface with another library or functionality. |
| Article 22 [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | See "GDPR."                                                  |
| Artificial Intelligence (AI) [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Good luck defining this term. ;-) We can talk about it in class.  (And/or see "[Challenges for an Ontology of Artificial Intelligence](https://www.asa3.org/ASA/PSCF/2019/PSCF6-19Hawley.pdf)" by S.H. Hawley, 2019.) |
| Attention [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | ...we'll get to this in...October.                           |
| Augmentation [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | i.e. Data augmentation. Increase the effective size of a training dataset by performing transformations on existing data to produce new data. Examples include changing the dimensions or brightness of an image, adding noise, flipping the phase of audio. Usually these are tranformations which would leave the intended model output unchanged, however this is not always the case. |
| AWS [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Amazon Web Services. Popular -- but by no means the only -- cloud computing service. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)B |                                                              |
| Term                                                         | Definition                                                   |
| Batch [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | aka "mini-batch". A number of inputs grouped together and run through the GPU at the same time. The first dimension of a data input array. Batch size: How many "points" of input data are included in a batch. Smaller GPUs require smaller batch sizes or you get OOM ("Out of Memory") errors from CUDA. |
| Bias [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this. ;-)                                  |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)C |                                                              |
| Term                                                         | Definition                                                   |
| Classification [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Producing a category label. ("What kind of thing is this?" "Dogs vs. Cats")Classification model: A model with a discrete set of (categorical) outputs.In machine learning, classification models are typically created from a regression model plus a threshold value or some other inter-class decision boundary. |
| CNN / ConvNet [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Convolutional Neural Network. An architecture in which weights are shared across an image or sequence. A neural network made up of convolutional operators. A simple convolution would be a running average, or an image processing algorithm like a gaussian blur, where some "kernel" is run all over a sequence/image. In the case of CNNs, the kernels are learned during the training process. |
| Colab [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | [Google Collaboratory](https://colab.research.google.com/). Our (free) computing platform for this course. Sometimes used to refer to an individual notebook on Colab. "Colab Pro": worth canceling Netflix for. ;-) |
| Command Line [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Usually we will use this to mean a UNIX "shell", of the sort one sees in a "Terminal" app. Unix commands are executed in Colab by preceding with a "!" symbol. Examples "!ls", "!pip install mrspuff". |
| Cost function [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | See "Loss".                                                  |
| CPU [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Central Processing Unit. Normal/main computer processor. What you *don't* want to try training your DL model on, but you might deploy a trained model on. Slow. |
| CUDA [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | The low-level computing library used for computing with GPUs. Made by NVIDIA Corporation, and only works on NVIDIA GPUs. AMD GPUs can use OpenCL but it's nowhere near as mature as CUDA.  (No idea what CUDA stands for as I write this.) |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)D |                                                              |
| Term                                                         | Definition                                                   |
| Deep Learning (DL) [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Training neural networks consisting of multiple hidden layers of neurons. Where "earlier" layers tend to learn simple things and later layers tend to compose results from multiple earlier layers. Tends to give rise to hierarchical structuring of capabilities. A term coined ca. 2010 by Geoffrey Hinton to avert the stigma of "neural networks." See ["Deep Learning for AI"](https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext) by Bengio, Lecun, and Hinton, 2021: https://cacm.acm.org/magazines/2021/7/253464-deep-learning-for-ai/fulltext |
| Derivative [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Rate of change at a particilar point. The slope of the line tangent to a curve at a given point. Related: Gradient. |
| Differential Privacy [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this                                       |
| Dot product [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Elementwise multiplication followed by a sum. So named because it's denoted by the "dot" symbol. Example: ![open parentheses x subscript 1 comma x subscript 2 comma x subscript 3 close parentheses times left parenthesis w subscript 1 comma w subscript 2 comma w subscript 3 right parenthesis space equals space x subscript 1 w subscript 1 space plus thin space x subscript 2 w subscript 2 space plus thin space x subscript 3 w subscript 3](https://belmont.blackboard.com/bbcswebdav/pid-90778-dt-course-rid-33087720_1/xid-33087720_1).Can be performed with two vectors, or a matrix row and a column vector, or a row vector and a matrix column, or more generally as a shorthand for matrix-matrix multiplication. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)F |                                                              |
| Term                                                         | Definition                                                   |
| Fairness [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back. ;-) lots of definitions of fairness.         |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)G |                                                              |
| Term                                                         | Definition                                                   |
| GDPR [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | The General Data Protection Regulation of the European Union (EU), especially Article 22, which lays out the requirements that automated decision-making systems used in government must be "explainable". Also includes provision for data protection such as privacy and the "right to be forgotten." |
| GPU [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Graphics Processing Unit - computer hardware systems originally designed for scene-rendering in video games, yet their massively parallel computing capabilties make them ideal for the matrix multiplications inherent in Deep Learning. |
| Gradient Descent [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | An optimization procedure that seeks to find a minimum of a function by proceding "downhill" in a series of steps from some (usually random) starting point. It is the primary method by which neural networks are trained, i.e. minimizing the loss function by following the gradient with respect to the model weights. |
| GUI / "gooey" [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Graphical User Interface. Many systems we use won't have a GUI, but some of the more user-friendly demos will. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)H |                                                              |
| Term                                                         | Definition                                                   |
| Hyperparameters [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Parameters of a neural network system that are *not* learned during training by gradient descent. Examples: batch size, layer width |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)L |                                                              |
| Term                                                         | Definition                                                   |
| Layer [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this. Everything's a layer. ;-)            |
| Loss [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | A quantity that measures the dissimilarity between a model's output and the intended result. Train deep neural networks amounts to minimizing the loss (via applying Gradient Descent and varying the model weights) over a "training dataset" of inputs. The loss must be a continuous function of inputs and of model weights. Examples: Mean Squared Error, Binary Cross-Entropy. |
| LSTM [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Long Short-Term Memory: An architecture use for sequence modeling (text/audio) in which neurons carry an internal "state" that can serve as a (semi-)persistent memory state as the model processes the sequence. LSTMs have largely been supplanted by Transformers but can still be quite useful. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)M |                                                              |
| Term                                                         | Definition                                                   |
| Machine Learning (ML) [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | An approach to AI in which a system "learns" from available data, where learning is defined in terms of *optimization*: minimizing a loss or maximizing a series of rewards. DL is a subset of ML.The term "machine learning" was originally coined by [Arthur Samuel](https://en.wikipedia.org/wiki/Arthur_Samuel) in the 1950s as being an approach distinct from the "AI" approach of Marvin Minsky and collaborators/predecessors, though nowadays ML is generally regarded as forming a subset of AI. |
| Matrix [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | An array of numbers, typically two-dimensional (i.e. rows and columns). In DL & CS, a vector is a 1D matrix and a "tensor" is (usually) a 3D matrix (e.g. a cube of numbers). (Note: In Physics & Math, a tensor *can be represented* by a matrix *in a particular coordinate system*, but a tensor has properties that a mere matrix does not. In this course I will generally avoid saying "tensor" because of this distinction, but Google and some other people in ML like to say it, e.g. "Tensorflow") |
| Matrix Multiplication (MM) [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | A series of dot products (see "Dot Product") between the rows of the first matrix and the columns of the second matrix. Produces a new matrix. In MM, the number of columns of the first matrix has to match the number of rows in the second matrix (or else there's no way it would work). Does not "commute", i.e. it matters what the order of the two matrices is. |
| MLP [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Multi-Layer Perceptron. A simple neural network consisting of an input layer, a hidden layer, and an output layer, with two weight layers in between. An MLP is a "shallow" network, not a "deep" one. |
| mrspuff [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | "Mrs. Puff", a flounder who runs a school in Bikini Bottom, and/or the best Python library for learning deep learning. A glorious work in progress. ;-) |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)N |                                                              |
| Term                                                         | Definition                                                   |
| Neural Network [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Artificial Neural Network, which for this course the "artificial" is implied.  A directed a cyclic graph of layers artificial neurons, which are just matrix multipliers with some nonlinear activation applied at the end. |
| NLP [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Natural Language Processing. Catch-all term that includes any processing of text. Typically includes Computational Linguistics. For all your DL NLP model needs, [HuggingFace](https://huggingface.co/) is now the de-facto clearing house. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)P |                                                              |
| Term                                                         | Definition                                                   |
| Parameters [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this                                       |
| PCA [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Principal Component Analysis. A dimensionality-reduction technique that functions as a data-reduction technique, in which we "project" data points along axes where there's not much variance, in order to retain only the most important variations in the data. PCA is a linear transformation. See Dr. Hawley's blog post, "[PCA from Scratch](https://drscotthawley.github.io/blog/2019/12/21/PCA-From-Scratch.html)". Not a deep learning technique, but good to know about, as it sometimes gets used as a pre-processing step when deploying on CPUs. |
| PR [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Pull Request. A GitHub term for when you submit code to help improve a repository. Example: "I'm so excited! I submitted a PR for mrspuff and it got accepted!" |
| Privacy [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | should add a reasonable working definition of privacy, even though this is somewhat of a contested space |
| PyTorch [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | The deep learning library / framework we will make heave use of in this course. Currently the most popular and enjoys the most widespread support. Other DL frameworks include Tensorflow/Keras (populary is waning) and JAX (popularity increasing quickly in the research world but not yet in industry, not ready for students).FastAI is currently built "on top of" PyTorch. Note that in actual code it's "torch" not "pytorch", i.e. "import torch" not "import pytorch". |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)R |                                                              |
| Term                                                         | Definition                                                   |
| Random Forest [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | A different method of machine learning for performing regression and/or classification. Not based on neural networks, but rather a "forest" of "random" decision trees. We won't be covering these in this course. "Boosted Trees" and XGBOOST are heavily used in industry for machine learning applications. But Deep Learning can do as well. ;-) |
| Rectifier [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Something that only allows non-negative values to "pass through". In DL, the "ReLU" (Rectified Linear Unit) activation is the dominant activation function in use today. ReLU(x) = max(x, 0). |
| Regression [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Curve-fitting. Regression model: a model with a continuously-varying (numerical) output.Examples:Linear regression: Fitting a line to a set of data points. ("y = mx+b", where you find m and b). Logistic regression: Like linear regression but you fit a S-shaped curve ("logistic sigmoid", ![y space equals space fraction numerator 1 over denominator 1 plus e to the power of negative x end exponent end fraction](https://belmont.blackboard.com/bbcswebdav/pid-90778-dt-course-rid-33087357_1/xid-33087357_1)) to data points that are either 0 or 1. Used to predict probabilities for binary (yes/no, true/false) classification. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)S |                                                              |
| Term                                                         | Definition                                                   |
| Semi-Supervised or Self-Supervised Learning [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Instead of labels supplied by human beings, correct answers are arrived at through some other process.Examples:learning to model laguage by predicting the next word in a sequence of text, or predicting what word goes in between other wordslearning to recognize images by performing a set of transformations (or "augmentations") to the images which should produce the same resultlearning to transcribe audio of musical percussion by minimizing the difference between original raw audio and a track synthesized from MIDI samples. "The future is self-supervised." -- Yann LeCun |
| Supervised Learning [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | A machine learning paradign in which correct answers "labels" are supplied by human beings. Supervised learning is often an entry point for many people into the world of Machine Learning, however most data in the real world is not already labeled, and getting it labeled can be time consuming and expensive. |
| Surveillance [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this. Generally, what AI is great at. ;-)  |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)T |                                                              |
| Term                                                         | Definition                                                   |
| Tensor [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | see Matrix                                                   |
| TPU [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Tensor Processing Unit. Special units made by Google for performing DL-type computations (i.e. matrix multiplications) at lower power / higher efficiency than GPUs.(We don't get to use these. Don't select "TPU" in Colab; it won't work.) |
| Transfer Learning [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this                                       |
| Transformer [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | An arcitechture used for processing sequence models* that makes use of "Attention" to focus the processing on certain parts of the input stream. Have come to dominate NLP and many other areas of DL research in the past few years. Examples: BERT, GPT-2, GPT-3.*though also images as sequences of pixels) |
| Transparency [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this.                                      |
| Transpose [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | An operation where you swap the rows & columns of a matrix. Usually used in DL to make the dimensions work out right for matrix multiplication. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)V |                                                              |
| Term                                                         | Definition                                                   |
| Vector [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | (In DL and Computer Science): A one-dimensional array of numbers. (In Math and Physics): A quantity with magnitude and direction, e.g. an "arrow". The two ways of regarding a vector can be unified if we view the set of numbers as describing the (x,y,z,...) coordinates of a *point* in some multidimensional space. The "proper" math/physics vector would then point from the origin to that point. |
| VRAM [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | Video RAM (Random Access Memory): How much data/model/stuff you can fit on a GPU. More is better. Typical consumer GPUs have 8GB to 12GB of VRAM, whereas commercial/research grade have 16GB, 24GB, or more. |
| [![img](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/arrow_up_li.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#topOfPage)W |                                                              |
| Term                                                         | Definition                                                   |
| Weights [![Click for more options](https://learn.content.blackboardcdn.com/3900.19.0-rel.36+070b377/images/ci/icons/cmlink_generic.gif)](https://belmont.blackboard.com/webapps/blackboard/glossary/links/glossary_manager.jsp?course_id=_90778_1&mode=cpview#contextMenu) | will come back to this                                       |
